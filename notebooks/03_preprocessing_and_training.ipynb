{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Pre-Processing and Training Data<a id='3_Pre-Processing_and_Training_Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Contents<a id='3.1_Contents'></a>\n",
    "* [3 Pre-Processing and Training Data](#3_Pre-Processing_and_Training_Data)\n",
    "  * [3.1 Imports](#3.1_Imports)\n",
    "  * [3.2 Load Data](#3.4_Load_Data)\n",
    "  * [3.3](#3.5_One-Hot_Encoding)\n",
    "  * [3.4](#3.6_Logistic_Regression)\n",
    "  * [3.5](#3.7_Random_Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Imports<a id='3.3_Imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "import datetime\n",
    "\n",
    "pd.set_option('display.max_columns',50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Load Data<a id='3.4_Load_Data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>repay_fail</th>\n",
       "      <th>annual_inc_log</th>\n",
       "      <th>revol_bal_log</th>\n",
       "      <th>years_of_credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2500.00</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.98</td>\n",
       "      <td>85.42</td>\n",
       "      <td>4 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>20004.00</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>other</td>\n",
       "      <td>MI</td>\n",
       "      <td>19.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2000-08-05</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>981.00</td>\n",
       "      <td>21.30</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000.00</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.95</td>\n",
       "      <td>175.67</td>\n",
       "      <td>4 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>59000.00</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NY</td>\n",
       "      <td>19.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1994-04-01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18773.00</td>\n",
       "      <td>99.90</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1</td>\n",
       "      <td>10.99</td>\n",
       "      <td>9.84</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7000.00</td>\n",
       "      <td>36 months</td>\n",
       "      <td>9.91</td>\n",
       "      <td>225.58</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>53796.00</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>other</td>\n",
       "      <td>TX</td>\n",
       "      <td>10.80</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3269.00</td>\n",
       "      <td>47.20</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.89</td>\n",
       "      <td>8.09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000.00</td>\n",
       "      <td>36 months</td>\n",
       "      <td>5.42</td>\n",
       "      <td>60.32</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.00</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NY</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1975-01-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3600.00</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.25</td>\n",
       "      <td>116.59</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>675048.00</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>other</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1998-04-01</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>13.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt       term  int_rate  installment emp_length home_ownership  \\\n",
       "3    2500.00  36 months     13.98        85.42    4 years           RENT   \n",
       "4    5000.00  36 months     15.95       175.67    4 years           RENT   \n",
       "5    7000.00  36 months      9.91       225.58  10+ years       MORTGAGE   \n",
       "6    2000.00  36 months      5.42        60.32  10+ years           RENT   \n",
       "7    3600.00  36 months     10.25       116.59  10+ years       MORTGAGE   \n",
       "\n",
       "   annual_inc verification_status             purpose addr_state   dti  \\\n",
       "3    20004.00        Not Verified               other         MI 19.86   \n",
       "4    59000.00        Not Verified  debt_consolidation         NY 19.57   \n",
       "5    53796.00        Not Verified               other         TX 10.80   \n",
       "6    30000.00        Not Verified  debt_consolidation         NY  3.60   \n",
       "7   675048.00        Not Verified               other         AL  1.55   \n",
       "\n",
       "   delinq_2yrs earliest_cr_line  inq_last_6mths  open_acc  pub_rec  revol_bal  \\\n",
       "3         0.00       2000-08-05            5.00      7.00     0.00     981.00   \n",
       "4         0.00       1994-04-01            1.00      7.00     0.00   18773.00   \n",
       "5         3.00       1998-03-01            3.00      7.00     0.00    3269.00   \n",
       "6         0.00       1975-01-01            0.00      7.00     0.00       0.00   \n",
       "7         0.00       1998-04-01            4.00      8.00     0.00       0.00   \n",
       "\n",
       "   revol_util  total_acc  repay_fail  annual_inc_log  revol_bal_log  \\\n",
       "3       21.30      10.00           0            9.90           6.89   \n",
       "4       99.90      15.00           1           10.99           9.84   \n",
       "5       47.20      20.00           0           10.89           8.09   \n",
       "6        0.00      15.00           0           10.31           0.00   \n",
       "7        0.00      25.00           0           13.42           0.00   \n",
       "\n",
       "   years_of_credit  \n",
       "3                0  \n",
       "4                6  \n",
       "5                2  \n",
       "6               25  \n",
       "7                2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explored_data = pd.read_csv('../data/processed/explored_data.csv', index_col=0)\n",
    "explored_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 One-Hot Encoding<a id='3.5_One-Hot_Encoding'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38415 entries, 3 to 38480\n",
      "Data columns (total 35 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   loan_amnt                            38415 non-null  float64\n",
      " 1   int_rate                             38415 non-null  float64\n",
      " 2   installment                          38415 non-null  float64\n",
      " 3   annual_inc                           38415 non-null  float64\n",
      " 4   purpose                              38415 non-null  object \n",
      " 5   addr_state                           38415 non-null  object \n",
      " 6   dti                                  38415 non-null  float64\n",
      " 7   delinq_2yrs                          38415 non-null  float64\n",
      " 8   earliest_cr_line                     38415 non-null  object \n",
      " 9   inq_last_6mths                       38415 non-null  float64\n",
      " 10  open_acc                             38415 non-null  float64\n",
      " 11  pub_rec                              38415 non-null  float64\n",
      " 12  revol_bal                            38415 non-null  float64\n",
      " 13  revol_util                           38415 non-null  float64\n",
      " 14  total_acc                            38415 non-null  float64\n",
      " 15  repay_fail                           38415 non-null  int64  \n",
      " 16  annual_inc_log                       38415 non-null  float64\n",
      " 17  revol_bal_log                        38415 non-null  float64\n",
      " 18  years_of_credit                      38415 non-null  int64  \n",
      " 19  term_60 months                       38415 non-null  uint8  \n",
      " 20  emp_length_10+ years                 38415 non-null  uint8  \n",
      " 21  emp_length_2 years                   38415 non-null  uint8  \n",
      " 22  emp_length_3 years                   38415 non-null  uint8  \n",
      " 23  emp_length_4 years                   38415 non-null  uint8  \n",
      " 24  emp_length_5 years                   38415 non-null  uint8  \n",
      " 25  emp_length_6 years                   38415 non-null  uint8  \n",
      " 26  emp_length_7 years                   38415 non-null  uint8  \n",
      " 27  emp_length_8 years                   38415 non-null  uint8  \n",
      " 28  emp_length_9 years                   38415 non-null  uint8  \n",
      " 29  emp_length_< 1 year                  38415 non-null  uint8  \n",
      " 30  home_ownership_OTHER                 38415 non-null  uint8  \n",
      " 31  home_ownership_OWN                   38415 non-null  uint8  \n",
      " 32  home_ownership_RENT                  38415 non-null  uint8  \n",
      " 33  verification_status_Source Verified  38415 non-null  uint8  \n",
      " 34  verification_status_Verified         38415 non-null  uint8  \n",
      "dtypes: float64(14), int64(2), object(3), uint8(16)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "desired_cat_feat = ['term', 'emp_length', 'home_ownership', 'verification_status']\n",
    "df_encoded = pd.get_dummies(explored_data, columns = desired_cat_feat, drop_first=True)\n",
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(columns=['addr_state','purpose','earliest_cr_line','repay_fail'])\n",
    "y = df_encoded.repay_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [03:37<00:00,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4355, number of negative: 24456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2521\n",
      "[LightGBM] [Info] Number of data points in the train set: 28811, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151158 -> initscore=-1.725551\n",
      "[LightGBM] [Info] Start training from score -1.725551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.77</td>\n",
       "      <td>58.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.77</td>\n",
       "      <td>53.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>9.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>80.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "NearestCentroid                    0.64               0.63     0.63      0.69   \n",
       "PassiveAggressiveClassifier        0.77               0.55     0.55      0.77   \n",
       "GaussianNB                         0.81               0.55     0.55      0.79   \n",
       "Perceptron                         0.80               0.55     0.55      0.78   \n",
       "QuadraticDiscriminantAnalysis      0.81               0.54     0.54      0.79   \n",
       "LabelSpreading                     0.77               0.53     0.53      0.77   \n",
       "LabelPropagation                   0.77               0.53     0.53      0.77   \n",
       "ExtraTreeClassifier                0.75               0.53     0.53      0.76   \n",
       "DecisionTreeClassifier             0.74               0.53     0.53      0.75   \n",
       "KNeighborsClassifier               0.84               0.52     0.52      0.79   \n",
       "XGBClassifier                      0.84               0.52     0.52      0.79   \n",
       "BernoulliNB                        0.84               0.51     0.51      0.79   \n",
       "BaggingClassifier                  0.84               0.51     0.51      0.79   \n",
       "LGBMClassifier                     0.85               0.51     0.51      0.78   \n",
       "ExtraTreesClassifier               0.85               0.50     0.50      0.78   \n",
       "RandomForestClassifier             0.85               0.50     0.50      0.78   \n",
       "LinearDiscriminantAnalysis         0.85               0.50     0.50      0.78   \n",
       "AdaBoostClassifier                 0.85               0.50     0.50      0.78   \n",
       "LogisticRegression                 0.85               0.50     0.50      0.78   \n",
       "CalibratedClassifierCV             0.85               0.50     0.50      0.78   \n",
       "SVC                                0.85               0.50     0.50      0.78   \n",
       "RidgeClassifier                    0.85               0.50     0.50      0.78   \n",
       "RidgeClassifierCV                  0.85               0.50     0.50      0.78   \n",
       "LinearSVC                          0.85               0.50     0.50      0.78   \n",
       "DummyClassifier                    0.85               0.50     0.50      0.78   \n",
       "SGDClassifier                      0.85               0.50     0.50      0.78   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "NearestCentroid                      0.04  \n",
       "PassiveAggressiveClassifier          0.08  \n",
       "GaussianNB                           0.05  \n",
       "Perceptron                           0.07  \n",
       "QuadraticDiscriminantAnalysis        0.07  \n",
       "LabelSpreading                      58.00  \n",
       "LabelPropagation                    53.62  \n",
       "ExtraTreeClassifier                  0.08  \n",
       "DecisionTreeClassifier               0.71  \n",
       "KNeighborsClassifier                 0.55  \n",
       "XGBClassifier                        0.27  \n",
       "BernoulliNB                          0.07  \n",
       "BaggingClassifier                    4.94  \n",
       "LGBMClassifier                       0.22  \n",
       "ExtraTreesClassifier                 3.98  \n",
       "RandomForestClassifier               9.16  \n",
       "LinearDiscriminantAnalysis           0.14  \n",
       "AdaBoostClassifier                   1.98  \n",
       "LogisticRegression                   0.07  \n",
       "CalibratedClassifierCV               0.34  \n",
       "SVC                                 80.52  \n",
       "RidgeClassifier                      0.05  \n",
       "RidgeClassifierCV                    0.07  \n",
       "LinearSVC                            2.52  \n",
       "DummyClassifier                      0.04  \n",
       "SGDClassifier                        0.17  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Logistic Regression<a id='3.6_Logistic_Regression'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the steps\n",
    "# steps = [(\"scaler\", StandardScaler()),\n",
    "#          (\"logreg\", LogisticRegression())]\n",
    "# pipeline = Pipeline(steps)\n",
    "\n",
    "# # Create the parameter space\n",
    "# parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20),\n",
    "#              \"logreg__solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag']}\n",
    "\n",
    "# # Instantiate the grid search object\n",
    "# cv_log = GridSearchCV(pipeline, param_grid=parameters, scoring='recall')\n",
    "\n",
    "# # Fit to the training data\n",
    "# cv_log.fit(X_train, y_train)\n",
    "# print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired_cat_feat = ['term', 'emp_length', 'home_ownership', 'verification_status','purpose']\n",
    "# df_encoded_purpose = pd.get_dummies(explored_data, columns = desired_cat_feat, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_encoded_purpose.drop(columns=['addr_state','earliest_cr_line','repay_fail'])\n",
    "# y = df_encoded_purpose.repay_fail\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47, stratify=y)\n",
    "\n",
    "# # Build the steps\n",
    "# steps = [(\"scaler\", StandardScaler()),\n",
    "#          (\"logreg\", LogisticRegression())]\n",
    "# pipeline = Pipeline(steps)\n",
    "\n",
    "# # Create the parameter space\n",
    "# parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20),\n",
    "#              \"logreg__solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag']}\n",
    "\n",
    "# # Instantiate the grid search object\n",
    "# cv_log = GridSearchCV(pipeline, param_grid=parameters, scoring='recall')\n",
    "\n",
    "# # Fit to the training data\n",
    "# cv_log.fit(X_train, y_train)\n",
    "# print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired_cat_feat = ['term', 'emp_length', 'home_ownership', 'verification_status','purpose','addr_state']\n",
    "# df_encoded_all = pd.get_dummies(explored_data, columns = desired_cat_feat, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_encoded_all.drop(columns=['earliest_cr_line','repay_fail'])\n",
    "# y = df_encoded_all.repay_fail\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47, stratify=y)\n",
    "\n",
    "# # Build the steps\n",
    "# steps = [(\"scaler\", StandardScaler()),\n",
    "#          (\"logreg\", LogisticRegression())]\n",
    "# pipeline = Pipeline(steps)\n",
    "\n",
    "# # Create the parameter space\n",
    "# parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20),\n",
    "#              \"logreg__solver\": ['newton-cg', 'lbfgs', 'liblinear']}\n",
    "\n",
    "# # Instantiate the grid search object\n",
    "# cv_log = GridSearchCV(pipeline, param_grid=parameters, scoring='recall')\n",
    "\n",
    "# # Fit to the training data\n",
    "# cv_log.fit(X_train, y_train)\n",
    "# print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.7 Random Forest<a id='3.7_Random_Forest'><a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_encoded.drop(columns=['addr_state','purpose','earliest_cr_line','repay_fail'])\n",
    "# y = df_encoded.repay_fail\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47, stratify=y)\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['sqrt', 'log2']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# cv_rf = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, \n",
    "#                         random_state=47, n_jobs = -1, scoring='recall')\n",
    "# # Fit the random search model\n",
    "# cv_rf.fit(X_train, y_train)\n",
    "# print(cv_rf.best_score_, \"\\n\", cv_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_encoded_purpose.drop(columns=['addr_state','earliest_cr_line','repay_fail'])\n",
    "# y = df_encoded_purpose.repay_fail\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47, stratify=y)\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['sqrt', 'log2']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# cv_rf_2 = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, \n",
    "#                         random_state=47, n_jobs = -1, scoring='recall')\n",
    "# # Fit the random search model\n",
    "# cv_rf_2.fit(X_train, y_train)\n",
    "# print(cv_rf_2.best_score_, \"\\n\", cv_rf_2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_encoded_all.drop(columns=['earliest_cr_line','repay_fail'])\n",
    "# y = df_encoded_all.repay_fail\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47, stratify=y)\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['sqrt', 'log2']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# cv_rf_3 = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, \n",
    "#                         random_state=47, n_jobs = -1, scoring='recall')\n",
    "# # Fit the random search model\n",
    "# cv_rf_3.fit(X_train, y_train)\n",
    "# print(cv_rf_3.best_score_, \"\\n\", cv_rf_3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "1. https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "2. https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
