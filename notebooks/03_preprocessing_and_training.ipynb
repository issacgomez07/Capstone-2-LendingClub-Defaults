{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Pre-Processing and Training Data<a id='3_Pre-Processing_and_Training_Data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Contents<a id='3.1_Contents'></a>\n",
    "* [3 Pre-Processing and Training Data](#3_Pre-Processing_and_Training_Data)\n",
    "  * [3.1 Imports](#3.1_Imports)\n",
    "  * [3.2 Load Data](#3.4_Load_Data)\n",
    "  * [3.3](#3.5_One-Hot_Encoding)\n",
    "  * [3.4](#3.6_Logistic_Regression)\n",
    "  * [3.5](#3.7_Random_Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Imports<a id='3.3_Imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\notis\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlazypredict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSupervised\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyClassifier\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m     20\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_param_validation.py:908\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    909\u001b[0m     HasMethods,\n\u001b[0;32m    910\u001b[0m     Hidden,\n\u001b[0;32m    911\u001b[0m     Interval,\n\u001b[0;32m    912\u001b[0m     Options,\n\u001b[0;32m    913\u001b[0m     StrOptions,\n\u001b[0;32m    914\u001b[0m     _ArrayLikes,\n\u001b[0;32m    915\u001b[0m     _Booleans,\n\u001b[0;32m    916\u001b[0m     _Callables,\n\u001b[0;32m    917\u001b[0m     _CVObjects,\n\u001b[0;32m    918\u001b[0m     _InstancesOf,\n\u001b[0;32m    919\u001b[0m     _IterablesNotString,\n\u001b[0;32m    920\u001b[0m     _MissingValues,\n\u001b[0;32m    921\u001b[0m     _NoneConstraint,\n\u001b[0;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[0;32m    923\u001b[0m     _RandomStates,\n\u001b[0;32m    924\u001b[0m     _SparseMatrices,\n\u001b[0;32m    925\u001b[0m     _VerboseHelper,\n\u001b[0;32m    926\u001b[0m     make_constraint,\n\u001b[0;32m    927\u001b[0m     validate_params,\n\u001b[0;32m    928\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\notis\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from xgboost import XGBClassifier\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import datetime\n",
    "\n",
    "pd.set_option('display.max_columns',50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Load Data<a id='3.4_Load_Data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>repay_fail</th>\n",
       "      <th>annual_inc_log</th>\n",
       "      <th>revol_bal_log</th>\n",
       "      <th>years_of_credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2500.00</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.98</td>\n",
       "      <td>85.42</td>\n",
       "      <td>4 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>20004.00</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>other</td>\n",
       "      <td>MI</td>\n",
       "      <td>19.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2000-08-05</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>981.00</td>\n",
       "      <td>21.30</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000.00</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.95</td>\n",
       "      <td>175.67</td>\n",
       "      <td>4 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>59000.00</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NY</td>\n",
       "      <td>19.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1994-04-01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18773.00</td>\n",
       "      <td>99.90</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1</td>\n",
       "      <td>10.99</td>\n",
       "      <td>9.84</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7000.00</td>\n",
       "      <td>36 months</td>\n",
       "      <td>9.91</td>\n",
       "      <td>225.58</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>53796.00</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>other</td>\n",
       "      <td>TX</td>\n",
       "      <td>10.80</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3269.00</td>\n",
       "      <td>47.20</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.89</td>\n",
       "      <td>8.09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000.00</td>\n",
       "      <td>36 months</td>\n",
       "      <td>5.42</td>\n",
       "      <td>60.32</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.00</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NY</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1975-01-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3600.00</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.25</td>\n",
       "      <td>116.59</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>675048.00</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>other</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1998-04-01</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>13.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt       term  int_rate  installment emp_length home_ownership  \\\n",
       "3    2500.00  36 months     13.98        85.42    4 years           RENT   \n",
       "4    5000.00  36 months     15.95       175.67    4 years           RENT   \n",
       "5    7000.00  36 months      9.91       225.58  10+ years       MORTGAGE   \n",
       "6    2000.00  36 months      5.42        60.32  10+ years           RENT   \n",
       "7    3600.00  36 months     10.25       116.59  10+ years       MORTGAGE   \n",
       "\n",
       "   annual_inc verification_status             purpose addr_state   dti  \\\n",
       "3    20004.00        Not Verified               other         MI 19.86   \n",
       "4    59000.00        Not Verified  debt_consolidation         NY 19.57   \n",
       "5    53796.00        Not Verified               other         TX 10.80   \n",
       "6    30000.00        Not Verified  debt_consolidation         NY  3.60   \n",
       "7   675048.00        Not Verified               other         AL  1.55   \n",
       "\n",
       "   delinq_2yrs earliest_cr_line  inq_last_6mths  open_acc  pub_rec  revol_bal  \\\n",
       "3         0.00       2000-08-05            5.00      7.00     0.00     981.00   \n",
       "4         0.00       1994-04-01            1.00      7.00     0.00   18773.00   \n",
       "5         3.00       1998-03-01            3.00      7.00     0.00    3269.00   \n",
       "6         0.00       1975-01-01            0.00      7.00     0.00       0.00   \n",
       "7         0.00       1998-04-01            4.00      8.00     0.00       0.00   \n",
       "\n",
       "   revol_util  total_acc  repay_fail  annual_inc_log  revol_bal_log  \\\n",
       "3       21.30      10.00           0            9.90           6.89   \n",
       "4       99.90      15.00           1           10.99           9.84   \n",
       "5       47.20      20.00           0           10.89           8.09   \n",
       "6        0.00      15.00           0           10.31           0.00   \n",
       "7        0.00      25.00           0           13.42           0.00   \n",
       "\n",
       "   years_of_credit  \n",
       "3                0  \n",
       "4                6  \n",
       "5                2  \n",
       "6               25  \n",
       "7                2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explored_data = pd.read_csv('../data/processed/explored_data.csv', index_col=0)\n",
    "explored_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 One-Hot Encoding<a id='3.5_One-Hot_Encoding'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38415 entries, 3 to 38480\n",
      "Data columns (total 95 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   loan_amnt                            38415 non-null  float64\n",
      " 1   int_rate                             38415 non-null  float64\n",
      " 2   installment                          38415 non-null  float64\n",
      " 3   annual_inc                           38415 non-null  float64\n",
      " 4   dti                                  38415 non-null  float64\n",
      " 5   delinq_2yrs                          38415 non-null  float64\n",
      " 6   earliest_cr_line                     38415 non-null  object \n",
      " 7   inq_last_6mths                       38415 non-null  float64\n",
      " 8   open_acc                             38415 non-null  float64\n",
      " 9   pub_rec                              38415 non-null  float64\n",
      " 10  revol_bal                            38415 non-null  float64\n",
      " 11  revol_util                           38415 non-null  float64\n",
      " 12  total_acc                            38415 non-null  float64\n",
      " 13  repay_fail                           38415 non-null  int64  \n",
      " 14  annual_inc_log                       38415 non-null  float64\n",
      " 15  revol_bal_log                        38415 non-null  float64\n",
      " 16  years_of_credit                      38415 non-null  int64  \n",
      " 17  term_60 months                       38415 non-null  uint8  \n",
      " 18  emp_length_10+ years                 38415 non-null  uint8  \n",
      " 19  emp_length_2 years                   38415 non-null  uint8  \n",
      " 20  emp_length_3 years                   38415 non-null  uint8  \n",
      " 21  emp_length_4 years                   38415 non-null  uint8  \n",
      " 22  emp_length_5 years                   38415 non-null  uint8  \n",
      " 23  emp_length_6 years                   38415 non-null  uint8  \n",
      " 24  emp_length_7 years                   38415 non-null  uint8  \n",
      " 25  emp_length_8 years                   38415 non-null  uint8  \n",
      " 26  emp_length_9 years                   38415 non-null  uint8  \n",
      " 27  emp_length_< 1 year                  38415 non-null  uint8  \n",
      " 28  home_ownership_OTHER                 38415 non-null  uint8  \n",
      " 29  home_ownership_OWN                   38415 non-null  uint8  \n",
      " 30  home_ownership_RENT                  38415 non-null  uint8  \n",
      " 31  verification_status_Source Verified  38415 non-null  uint8  \n",
      " 32  verification_status_Verified         38415 non-null  uint8  \n",
      " 33  addr_state_AL                        38415 non-null  uint8  \n",
      " 34  addr_state_AR                        38415 non-null  uint8  \n",
      " 35  addr_state_AZ                        38415 non-null  uint8  \n",
      " 36  addr_state_CA                        38415 non-null  uint8  \n",
      " 37  addr_state_CO                        38415 non-null  uint8  \n",
      " 38  addr_state_CT                        38415 non-null  uint8  \n",
      " 39  addr_state_DC                        38415 non-null  uint8  \n",
      " 40  addr_state_DE                        38415 non-null  uint8  \n",
      " 41  addr_state_FL                        38415 non-null  uint8  \n",
      " 42  addr_state_GA                        38415 non-null  uint8  \n",
      " 43  addr_state_HI                        38415 non-null  uint8  \n",
      " 44  addr_state_IA                        38415 non-null  uint8  \n",
      " 45  addr_state_ID                        38415 non-null  uint8  \n",
      " 46  addr_state_IL                        38415 non-null  uint8  \n",
      " 47  addr_state_IN                        38415 non-null  uint8  \n",
      " 48  addr_state_KS                        38415 non-null  uint8  \n",
      " 49  addr_state_KY                        38415 non-null  uint8  \n",
      " 50  addr_state_LA                        38415 non-null  uint8  \n",
      " 51  addr_state_MA                        38415 non-null  uint8  \n",
      " 52  addr_state_MD                        38415 non-null  uint8  \n",
      " 53  addr_state_ME                        38415 non-null  uint8  \n",
      " 54  addr_state_MI                        38415 non-null  uint8  \n",
      " 55  addr_state_MN                        38415 non-null  uint8  \n",
      " 56  addr_state_MO                        38415 non-null  uint8  \n",
      " 57  addr_state_MS                        38415 non-null  uint8  \n",
      " 58  addr_state_MT                        38415 non-null  uint8  \n",
      " 59  addr_state_NC                        38415 non-null  uint8  \n",
      " 60  addr_state_NE                        38415 non-null  uint8  \n",
      " 61  addr_state_NH                        38415 non-null  uint8  \n",
      " 62  addr_state_NJ                        38415 non-null  uint8  \n",
      " 63  addr_state_NM                        38415 non-null  uint8  \n",
      " 64  addr_state_NV                        38415 non-null  uint8  \n",
      " 65  addr_state_NY                        38415 non-null  uint8  \n",
      " 66  addr_state_OH                        38415 non-null  uint8  \n",
      " 67  addr_state_OK                        38415 non-null  uint8  \n",
      " 68  addr_state_OR                        38415 non-null  uint8  \n",
      " 69  addr_state_PA                        38415 non-null  uint8  \n",
      " 70  addr_state_RI                        38415 non-null  uint8  \n",
      " 71  addr_state_SC                        38415 non-null  uint8  \n",
      " 72  addr_state_SD                        38415 non-null  uint8  \n",
      " 73  addr_state_TN                        38415 non-null  uint8  \n",
      " 74  addr_state_TX                        38415 non-null  uint8  \n",
      " 75  addr_state_UT                        38415 non-null  uint8  \n",
      " 76  addr_state_VA                        38415 non-null  uint8  \n",
      " 77  addr_state_VT                        38415 non-null  uint8  \n",
      " 78  addr_state_WA                        38415 non-null  uint8  \n",
      " 79  addr_state_WI                        38415 non-null  uint8  \n",
      " 80  addr_state_WV                        38415 non-null  uint8  \n",
      " 81  addr_state_WY                        38415 non-null  uint8  \n",
      " 82  purpose_credit_card                  38415 non-null  uint8  \n",
      " 83  purpose_debt_consolidation           38415 non-null  uint8  \n",
      " 84  purpose_educational                  38415 non-null  uint8  \n",
      " 85  purpose_home_improvement             38415 non-null  uint8  \n",
      " 86  purpose_house                        38415 non-null  uint8  \n",
      " 87  purpose_major_purchase               38415 non-null  uint8  \n",
      " 88  purpose_medical                      38415 non-null  uint8  \n",
      " 89  purpose_moving                       38415 non-null  uint8  \n",
      " 90  purpose_other                        38415 non-null  uint8  \n",
      " 91  purpose_renewable_energy             38415 non-null  uint8  \n",
      " 92  purpose_small_business               38415 non-null  uint8  \n",
      " 93  purpose_vacation                     38415 non-null  uint8  \n",
      " 94  purpose_wedding                      38415 non-null  uint8  \n",
      "dtypes: float64(14), int64(2), object(1), uint8(78)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "desired_cat_feat = ['term', 'emp_length', 'home_ownership', 'verification_status', 'addr_state', 'purpose']\n",
    "df_encoded = pd.get_dummies(explored_data, columns = desired_cat_feat, drop_first=True)\n",
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.rename(columns={\"emp_length_< 1 year\": \"emp_length_0_years\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(columns=['earliest_cr_line','repay_fail'])\n",
    "y = df_encoded.repay_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 28/29 [32:23<00:37, 37.03s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4355, number of negative: 24456\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2689\n",
      "[LightGBM] [Info] Number of data points in the train set: 28811, number of used features: 87\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.151158 -> initscore=-1.725551\n",
      "[LightGBM] [Info] Start training from score -1.725551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [32:24<00:00, 67.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>873.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>9.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>8.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>13.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>13.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>209.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "NearestCentroid                    0.66               0.64     0.64      0.70   \n",
       "Perceptron                         0.73               0.55     0.55      0.75   \n",
       "DecisionTreeClassifier             0.75               0.53     0.53      0.75   \n",
       "ExtraTreeClassifier                0.76               0.53     0.53      0.76   \n",
       "PassiveAggressiveClassifier        0.77               0.53     0.53      0.76   \n",
       "BernoulliNB                        0.84               0.52     0.52      0.79   \n",
       "LabelPropagation                   0.77               0.52     0.52      0.76   \n",
       "XGBClassifier                      0.84               0.52     0.52      0.79   \n",
       "LinearDiscriminantAnalysis         0.85               0.51     0.51      0.79   \n",
       "BaggingClassifier                  0.84               0.51     0.51      0.79   \n",
       "KNeighborsClassifier               0.83               0.51     0.51      0.78   \n",
       "AdaBoostClassifier                 0.85               0.51     0.51      0.79   \n",
       "LGBMClassifier                     0.85               0.51     0.51      0.79   \n",
       "LogisticRegression                 0.85               0.51     0.51      0.78   \n",
       "CalibratedClassifierCV             0.85               0.51     0.51      0.78   \n",
       "GaussianNB                         0.16               0.50     0.50      0.07   \n",
       "ExtraTreesClassifier               0.85               0.50     0.50      0.78   \n",
       "QuadraticDiscriminantAnalysis      0.16               0.50     0.50      0.07   \n",
       "LinearSVC                          0.85               0.50     0.50      0.78   \n",
       "RandomForestClassifier             0.85               0.50     0.50      0.78   \n",
       "RidgeClassifier                    0.85               0.50     0.50      0.78   \n",
       "RidgeClassifierCV                  0.85               0.50     0.50      0.78   \n",
       "SGDClassifier                      0.85               0.50     0.50      0.78   \n",
       "DummyClassifier                    0.85               0.50     0.50      0.78   \n",
       "SVC                                0.85               0.50     0.50      0.78   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "NearestCentroid                      0.20  \n",
       "Perceptron                           0.29  \n",
       "DecisionTreeClassifier               1.34  \n",
       "ExtraTreeClassifier                  0.23  \n",
       "PassiveAggressiveClassifier          0.27  \n",
       "BernoulliNB                          0.21  \n",
       "LabelPropagation                   873.33  \n",
       "XGBClassifier                        0.92  \n",
       "LinearDiscriminantAnalysis           1.13  \n",
       "BaggingClassifier                    9.60  \n",
       "KNeighborsClassifier                 1.60  \n",
       "AdaBoostClassifier                   3.55  \n",
       "LGBMClassifier                       0.79  \n",
       "LogisticRegression                   0.43  \n",
       "CalibratedClassifierCV               2.51  \n",
       "GaussianNB                           0.22  \n",
       "ExtraTreesClassifier                 8.78  \n",
       "QuadraticDiscriminantAnalysis        0.37  \n",
       "LinearSVC                           13.32  \n",
       "RandomForestClassifier              13.45  \n",
       "RidgeClassifier                      0.22  \n",
       "RidgeClassifierCV                    0.39  \n",
       "SGDClassifier                        0.92  \n",
       "DummyClassifier                      0.14  \n",
       "SVC                                209.64  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.to_csv('../data/processed/lazypredict_models.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Accuracy', 'Balanced Accuracy', 'ROC AUC', 'F1 Score', 'Time Taken'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>9.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>8.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>13.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>13.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>209.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>873.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "BernoulliNB                        0.84               0.52     0.52      0.79   \n",
       "LinearDiscriminantAnalysis         0.85               0.51     0.51      0.79   \n",
       "XGBClassifier                      0.84               0.52     0.52      0.79   \n",
       "BaggingClassifier                  0.84               0.51     0.51      0.79   \n",
       "AdaBoostClassifier                 0.85               0.51     0.51      0.79   \n",
       "LGBMClassifier                     0.85               0.51     0.51      0.79   \n",
       "LogisticRegression                 0.85               0.51     0.51      0.78   \n",
       "KNeighborsClassifier               0.83               0.51     0.51      0.78   \n",
       "CalibratedClassifierCV             0.85               0.51     0.51      0.78   \n",
       "ExtraTreesClassifier               0.85               0.50     0.50      0.78   \n",
       "LinearSVC                          0.85               0.50     0.50      0.78   \n",
       "RandomForestClassifier             0.85               0.50     0.50      0.78   \n",
       "RidgeClassifier                    0.85               0.50     0.50      0.78   \n",
       "RidgeClassifierCV                  0.85               0.50     0.50      0.78   \n",
       "DummyClassifier                    0.85               0.50     0.50      0.78   \n",
       "SVC                                0.85               0.50     0.50      0.78   \n",
       "SGDClassifier                      0.85               0.50     0.50      0.78   \n",
       "PassiveAggressiveClassifier        0.77               0.53     0.53      0.76   \n",
       "LabelPropagation                   0.77               0.52     0.52      0.76   \n",
       "ExtraTreeClassifier                0.76               0.53     0.53      0.76   \n",
       "DecisionTreeClassifier             0.75               0.53     0.53      0.75   \n",
       "Perceptron                         0.73               0.55     0.55      0.75   \n",
       "NearestCentroid                    0.66               0.64     0.64      0.70   \n",
       "QuadraticDiscriminantAnalysis      0.16               0.50     0.50      0.07   \n",
       "GaussianNB                         0.16               0.50     0.50      0.07   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "BernoulliNB                          0.21  \n",
       "LinearDiscriminantAnalysis           1.13  \n",
       "XGBClassifier                        0.92  \n",
       "BaggingClassifier                    9.60  \n",
       "AdaBoostClassifier                   3.55  \n",
       "LGBMClassifier                       0.79  \n",
       "LogisticRegression                   0.43  \n",
       "KNeighborsClassifier                 1.60  \n",
       "CalibratedClassifierCV               2.51  \n",
       "ExtraTreesClassifier                 8.78  \n",
       "LinearSVC                           13.32  \n",
       "RandomForestClassifier              13.45  \n",
       "RidgeClassifier                      0.22  \n",
       "RidgeClassifierCV                    0.39  \n",
       "DummyClassifier                      0.14  \n",
       "SVC                                209.64  \n",
       "SGDClassifier                        0.92  \n",
       "PassiveAggressiveClassifier          0.27  \n",
       "LabelPropagation                   873.33  \n",
       "ExtraTreeClassifier                  0.23  \n",
       "DecisionTreeClassifier               1.34  \n",
       "Perceptron                           0.29  \n",
       "NearestCentroid                      0.20  \n",
       "QuadraticDiscriminantAnalysis        0.37  \n",
       "GaussianNB                           0.22  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.sort_values(['F1 Score','Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 XGBoost Classifier<a id='3.6_XGBoost_Classifier'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91      8152\n",
      "           1       0.32      0.05      0.09      1452\n",
      "\n",
      "    accuracy                           0.84      9604\n",
      "   macro avg       0.59      0.52      0.50      9604\n",
      "weighted avg       0.77      0.84      0.79      9604\n",
      "\n",
      "XGBoost AUC:  0.6796859159441683\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "# Optionally, get prediction probabilities\n",
    "xgb_probs = xgb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Store the predictions in a DataFrame for comparison\n",
    "predictions_df = pd.DataFrame({\n",
    "    'TrueLabels': y_test,\n",
    "    'XGB_Predictions': xgb_predictions,\n",
    "    'XGB_Probs': xgb_probs,\n",
    "})\n",
    "\n",
    "# Evaluate predictions\n",
    "print(classification_report(y_test, xgb_predictions))\n",
    "print(\"XGBoost AUC: \", roc_auc_score(y_test, xgb_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Logistic Regression<a id='3.6_Logistic_Regression'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the steps\n",
    "# steps = [(\"scaler\", StandardScaler()),\n",
    "#          (\"logreg\", LogisticRegression())]\n",
    "# pipeline = Pipeline(steps)\n",
    "\n",
    "# # Create the parameter space\n",
    "# parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20),\n",
    "#              \"logreg__solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag']}\n",
    "\n",
    "# # Instantiate the grid search object\n",
    "# cv_log = GridSearchCV(pipeline, param_grid=parameters, scoring='recall')\n",
    "\n",
    "# # Fit to the training data\n",
    "# cv_log.fit(X_train, y_train)\n",
    "# print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired_cat_feat = ['term', 'emp_length', 'home_ownership', 'verification_status','purpose']\n",
    "# df_encoded_purpose = pd.get_dummies(explored_data, columns = desired_cat_feat, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_encoded_purpose.drop(columns=['addr_state','earliest_cr_line','repay_fail'])\n",
    "# y = df_encoded_purpose.repay_fail\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47, stratify=y)\n",
    "\n",
    "# # Build the steps\n",
    "# steps = [(\"scaler\", StandardScaler()),\n",
    "#          (\"logreg\", LogisticRegression())]\n",
    "# pipeline = Pipeline(steps)\n",
    "\n",
    "# # Create the parameter space\n",
    "# parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20),\n",
    "#              \"logreg__solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag']}\n",
    "\n",
    "# # Instantiate the grid search object\n",
    "# cv_log = GridSearchCV(pipeline, param_grid=parameters, scoring='recall')\n",
    "\n",
    "# # Fit to the training data\n",
    "# cv_log.fit(X_train, y_train)\n",
    "# print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired_cat_feat = ['term', 'emp_length', 'home_ownership', 'verification_status','purpose','addr_state']\n",
    "# df_encoded_all = pd.get_dummies(explored_data, columns = desired_cat_feat, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_encoded_all.drop(columns=['earliest_cr_line','repay_fail'])\n",
    "# y = df_encoded_all.repay_fail\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47, stratify=y)\n",
    "\n",
    "# # Build the steps\n",
    "# steps = [(\"scaler\", StandardScaler()),\n",
    "#          (\"logreg\", LogisticRegression())]\n",
    "# pipeline = Pipeline(steps)\n",
    "\n",
    "# # Create the parameter space\n",
    "# parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20),\n",
    "#              \"logreg__solver\": ['newton-cg', 'lbfgs', 'liblinear']}\n",
    "\n",
    "# # Instantiate the grid search object\n",
    "# cv_log = GridSearchCV(pipeline, param_grid=parameters, scoring='recall')\n",
    "\n",
    "# # Fit to the training data\n",
    "# cv_log.fit(X_train, y_train)\n",
    "# print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.7 Random Forest<a id='3.7_Random_Forest'><a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_encoded.drop(columns=['addr_state','purpose','earliest_cr_line','repay_fail'])\n",
    "# y = df_encoded.repay_fail\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47, stratify=y)\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['sqrt', 'log2']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# cv_rf = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, \n",
    "#                         random_state=47, n_jobs = -1, scoring='recall')\n",
    "# # Fit the random search model\n",
    "# cv_rf.fit(X_train, y_train)\n",
    "# print(cv_rf.best_score_, \"\\n\", cv_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_encoded_purpose.drop(columns=['addr_state','earliest_cr_line','repay_fail'])\n",
    "# y = df_encoded_purpose.repay_fail\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47, stratify=y)\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['sqrt', 'log2']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# cv_rf_2 = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, \n",
    "#                         random_state=47, n_jobs = -1, scoring='recall')\n",
    "# # Fit the random search model\n",
    "# cv_rf_2.fit(X_train, y_train)\n",
    "# print(cv_rf_2.best_score_, \"\\n\", cv_rf_2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_encoded_all.drop(columns=['earliest_cr_line','repay_fail'])\n",
    "# y = df_encoded_all.repay_fail\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=47, stratify=y)\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['sqrt', 'log2']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# cv_rf_3 = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, \n",
    "#                         random_state=47, n_jobs = -1, scoring='recall')\n",
    "# # Fit the random search model\n",
    "# cv_rf_3.fit(X_train, y_train)\n",
    "# print(cv_rf_3.best_score_, \"\\n\", cv_rf_3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "1. https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "2. https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
